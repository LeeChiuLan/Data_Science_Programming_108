SiteMap <- ggmap(twmap)+geom_point(data = sitedata_raw, aes(x=Longitude, y=Latitude,size=3.5))
SiteMap
library(ggplot2)
library(ggmap)
stopifnot(has_google_key()){
cat("register_google(key =\"xxxxx....\") Firstly")
}
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),zoom = 7, language = "zh-TW")
ggmap(twmap)
sitedata_raw<-read.csv("/Users/linda/Desktop/CS+X-108/20190711/空氣品質監測站Eng.csv", header=T, sep=",")
sitedata <- select(sitedata_raw, Name, Longitude,Latitude)
sitedata = sitedata[sitedata$Name != "",]    # remove empty row
SiteMap <- ggmap(twmap)+geom_point(data = sitedata, aes(x=Longitude, y=Latitude,size=3.5))
SiteMap
sitedata_raw<-read.csv("/Users/linda/Desktop/CS+X-108/20190711/空氣品質監測站Eng.csv", header=T, sep=",")
sitedata <- select(sitedata_raw, Name, Longitude,Latitude)
sitedata = sitedata[sitedata$Name != "",]    # remove empty row
SiteMap <- ggmap(twmap, darken = c(1,"green")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
SiteMap <- ggmap(twmap, darken = c(1,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
SiteMap <- ggmap(twmap, darken = c(0.5,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
SiteMap <- ggmap(twmap) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
#SiteMap <- ggmap(twmap, darken = c(0.5,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),zoom = 7, language = "zh-TW", maptype="roadmap")
#ggmap(twmap)
SiteMap <- ggmap(twmap) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
#SiteMap <- ggmap(twmap, darken = c(0.5,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
?apply(array, margin, ...)
library(dplyr)
library(rvest)
library(wordcloud)
install.packages("wordcloud")
install.packages("xml2")
library(dplyr)
library(rvest)
library(wordcloud)
install.packages("RColorBrewer")
install.packages("xml2")
install.packages("RColorBrewer")
library(dplyr)
library(rvest)
library(wordcloud)
library(xml2)
library(dplyr)
library(rvest)
library(wordcloud)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
rank_tag
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
cat(nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test=html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
source('~/Desktop/GitHub/Data_Science_Programming_108/Samples/WebSpider/BlogsMedical.R')
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- test
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, "li .rank-1")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0("li .rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 8   # get the top-10
for(i in 8:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 8   # get the top-10
for(i in 8:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- test
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
nodes
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- test
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- c(test)
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- c(test)
all_tag_nodes
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- c(test)
all_tag_nodes
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- rbind(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(tmcn)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(rvest)
library(xml2)
library(rvest)
# 抓取整個頁面內容
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
#找出在資料在頁面中的位置後提取資料
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
title <- html_text(tag_nodes) %>% iconv("UTF-8")
head(title)
str(title)
# 開始斷詞
cutter <- worker()
ccset<-cutter[title]
head(ccset)
# 轉成data.frame
raw_data <- data.frame(ccset %>% table)
head(raw_data)
# 排序 Top-6
raw_data[order(raw_data$Freq,decreasing = TRUE),]
freq <- table(raw_data)
head(sort(freq, decreasing=T))
wordcloud(names(freq), freq, min.freq = 1, scale=c(4,.2), max.words=200, random.order=FALSE, colors=brewer.pal(5,"Dark2"))
freq <- table(raw_data)
wordcloud(freg)
freq <- table(raw_data)
wordcloud(freq)
freq <- table(raw_data)
head(freq)
freq <- table(raw_data)
head(sort(freq, decreasing=T))
?worker
freq <- table(raw_data)
head(sort(freq, decreasing=T))
freq <- table(title)
head(sort(freq, decreasing=T))
wordcloud(freq, freq, min.freq = 1, scale=c(4,.2), max.words=200, random.order=FALSE, colors=brewer.pal(5,"Dark2"))
freq <- table(ccset)
head(sort(freq, decreasing=T))
wordcloud(freq, freq, min.freq = 1, scale=c(4,.2), max.words=200, random.order=FALSE, colors=brewer.pal(5,"Dark2"))
table(ccset)
data_in_table <- table(ccset)
# 轉成data.frame
raw_data <- data.frame(data_in_table)
head(raw_data)
library(dplyr)
library(tmcn)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(rvest)
library(xml2)
library(rvest)
# 抓取整個頁面內容
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
#找出在資料在頁面中的位置後提取資料
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
title <- html_text(tag_nodes) %>% iconv("UTF-8")
head(title)
str(title)
# 開始斷詞
cutter <- worker("tag")
itemName<-cutter[title]
head(itemName)
# table
data_in_table <- table(itemName)
# 轉成data.frame
raw_data <- data.frame(data_in_table)
head(raw_data)
# 排序 Top-6
raw_data[order(raw_data$Freq,decreasing = TRUE),]
# 文字雲
head(sort(data_in_table, decreasing=T))
wordcloud(data_in_table$itemName, data_in_table$Freq, min.freq = 1, scale=c(4,.2), max.words=200, random.order=FALSE, colors=brewer.pal(5,"Dark2"))
# 新增字典
dic = c("HBL")
new_user_word(cutter,dic)
library(dplyr)
library(tmcn)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(rvest)
library(xml2)
library(rvest)
# 抓取整個頁面內容
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
#找出在資料在頁面中的位置後提取資料
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
title <- html_text(tag_nodes) %>% iconv("UTF-8")
head(title)
str(title)
# 開始斷詞
cutter <- worker("tag")
itemName<-cutter[title]
head(itemName)
# table
data_in_table <- table(itemName)
# 轉成data.frame
raw_data <- data.frame(data_in_table)
head(raw_data)
# 排序 Top-6
raw_data[order(raw_data$Freq,decreasing = TRUE),]
# 文字雲
head(sort(data_in_table, decreasing=T))
wordcloud(data_in_table$itemName, data_in_table$Freq,
min.freq = 1, max.words=200, scale=c(4,.2),
random.order=FALSE, colors=brewer.pal(5,"Dark2"))
wordcloud(raw_data$itemName, raw_data$Freq,
min.freq = 1, max.words=200, scale=c(4,.2),
random.order=FALSE, colors=brewer.pal(5,"Dark2"))
par(family=(“Heiti TC Light”))
par(family=(“Heiti TC Light”))
par(family=("Heiti TC Light"))
wordcloud(raw_data$itemName, raw_data$Freq,
min.freq = 1, max.words=200, scale=c(4,.2),
random.order=FALSE, colors=brewer.pal(5,"Dark2"))
raw_data[order(raw_data$Freq,decreasing = TRUE),]
head(raw_data[order(raw_data$Freq,decreasing = TRUE),])
library(dplyr)
library(ggplot2)
library(ggmap)
stopifnot(has_google_key()){
cat("register_google(key =\"xxxxx....\") Firstly")
}
has_google_key()
google_key()
setwd("~/Desktop/GitHub/Data_Science_Programming_108/Samples/WebSpider")
