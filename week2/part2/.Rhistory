#head(sitedata)
# add a column - "Description"
Description=""
sitedata = cbind(sitedata, Description)
head(sitedata)
dim(sitedata)
#--------------- [DataSet] restaurant ---------------
restaurantdata <- select(restaurantdata_raw, Name, Px, Py, Description)
# rename the specified columns' name
names(restaurantdata)[names(restaurantdata) == "Px"] <- "Longitude"
names(restaurantdata)[names(restaurantdata) == "Py"] <- "Latitude"
head(restaurantdata)
dim(restaurantdata)
# merge [sie], [restaurant]
data = rbind(restaurantdata, sitedata)
dim(data)
library(kableExtra)
kable(head(data))
summary(data)
library(ggplot2)
library(ggmap)
stopifnot(has_google_key()){
cat("register_google(key =\"xxxxx....\") Firstly")
}
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),zoom = 7, language = "zh-TW")
sitedata_raw<-read.csv("/Users/linda/Desktop/CS+X-108/20190711/空氣品質監測站Eng.csv", header=T, sep=",")
SiteMap <- ggmap(twmap)+geom_point(data = sitedata_raw, aes(x=Longitude, y=Latitude,size=3.5))
SiteMap
library(ggplot2)
library(ggmap)
stopifnot(has_google_key()){
cat("register_google(key =\"xxxxx....\") Firstly")
}
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),zoom = 7, language = "zh-TW")
ggmap(twmap)
sitedata_raw<-read.csv("/Users/linda/Desktop/CS+X-108/20190711/空氣品質監測站Eng.csv", header=T, sep=",")
sitedata <- select(sitedata_raw, Name, Longitude,Latitude)
sitedata = sitedata[sitedata$Name != "",]    # remove empty row
SiteMap <- ggmap(twmap)+geom_point(data = sitedata, aes(x=Longitude, y=Latitude,size=3.5))
SiteMap
sitedata_raw<-read.csv("/Users/linda/Desktop/CS+X-108/20190711/空氣品質監測站Eng.csv", header=T, sep=",")
sitedata <- select(sitedata_raw, Name, Longitude,Latitude)
sitedata = sitedata[sitedata$Name != "",]    # remove empty row
SiteMap <- ggmap(twmap, darken = c(1,"green")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
SiteMap <- ggmap(twmap, darken = c(1,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
SiteMap <- ggmap(twmap, darken = c(0.5,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
SiteMap <- ggmap(twmap) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
#SiteMap <- ggmap(twmap, darken = c(0.5,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),zoom = 7, language = "zh-TW", maptype="roadmap")
#ggmap(twmap)
SiteMap <- ggmap(twmap) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
#SiteMap <- ggmap(twmap, darken = c(0.5,"white")) + geom_point(data = sitedata, aes(x = Longitude, y = Latitude), color="red")
SiteMap
?apply(array, margin, ...)
library(dplyr)
library(rvest)
library(wordcloud)
install.packages("wordcloud")
install.packages("xml2")
library(dplyr)
library(rvest)
library(wordcloud)
install.packages("RColorBrewer")
install.packages("xml2")
install.packages("RColorBrewer")
library(dplyr)
library(rvest)
library(wordcloud)
library(xml2)
library(dplyr)
library(rvest)
library(wordcloud)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
rank_tag
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
cat(nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test=html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
source('~/Desktop/GitHub/Data_Science_Programming_108/Samples/WebSpider/BlogsMedical.R')
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- test
rank <- 10   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, "li .rank-1")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0("li .rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- character(0)
rank <- 1   # get the top-10
for(i in 1:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 8   # get the top-10
for(i in 8:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
#all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-8")
test
all_tag_nodes <- character(0)
rank <- 8   # get the top-10
for(i in 8:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- c(all_tag_nodes, nodes)
}
nodes
all_tag_nodes[1]
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- test
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
nodes
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- test
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
head(all_tag_nodes)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- c(test)
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- c(test)
all_tag_nodes
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
append(all_tag_nodes, nodes)
}
all_tag_nodes
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
test
all_tag_nodes <- c(test)
all_tag_nodes
rank <- 10   # get the top-10
for(i in 2:rank){
rank_tag <- paste0(".rank-",i)
cat(rank_tag)
nodes <- html_node(full_page, rank_tag)
all_tag_nodes <- rbind(all_tag_nodes, nodes)
}
all_tag_nodes
setwd("~/Desktop/GitHub/Data_Science_Programming_108/week2/part2")
library(dplyr)
library(readxl)
library(geosphere)
sitedata_raw<-read.csv("../../Datasets/空氣品質監測站Eng.csv", header=T, sep=",")
AQIfile <- "../../Datasets/ATM00679_2019_0322_0430.xlsx"
AQIdata_raw <- read_xlsx(AQIfile)
head(AQIdata_raw)
#--------------- [DataSet] Site ---------------
sitedata <- select(sitedata_raw, Name, Longitude,Latitude) %>%
rename(SiteName=Name)
sitedata = sitedata[sitedata$SiteName != "",]    # remove empty row
dim(sitedata)
#sitedata$SiteName <- paste(sitedata$SiteName,"Site", sep="_")   #append "Site" to each $Name
head(sitedata)
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
cat(test)
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(dplyr)
library(xml2)
library(rvest)
library(wordcloud)
full_page <- read_html("https://www.pixnet.net/blog/articles/category/33")
full_page
test <- html_node(full_page, ".rank-1")
cat(test)
library(dplyr)
library(tmcn)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(rvest)
library(xml2)
library(rvest)
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
raw_data <-  html_nodes(full_page, ".boxTitle .listA .list_title") %>%
+ html_text() %>% iconv("UTF-8")
head(raw_data)
library(dplyr)
library(tmcn)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(rvest)
library(xml2)
library(rvest)
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
tags <- html_text() %>% iconv("UTF-8")
head(tags)
tags <- html_text(tag_nodes)
head(tags)
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
tags <- html_text(tag_nodes) %>% iconv("UTF-8")
head(tags)
head(raw_data)
title <- html_text(tag_nodes) %>% iconv("UTF-8")
head(title)
str(title)
cutter <- worker()
cutter(title)
# 抓取整個頁面內容
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
#找出在資料在頁面中的位置後提取資料
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
title <- html_text(tag_nodes) %>% iconv("UTF-8")
head(title)
str(title)
# 開始斷詞
cutter <- worker()
cutter(title)
# 開始斷詞
cutter <- worker()
cutter[title]
library(dplyr)
library(tmcn)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(rvest)
library(xml2)
library(rvest)
# 抓取整個頁面內容
full_page <- read_html("https://sports.ltn.com.tw/basketball/")
full_page
#找出在資料在頁面中的位置後提取資料
tag_nodes <-  html_nodes(full_page, ".boxTitle .listA .list_title")
head(tag_nodes)
title <- html_text(tag_nodes) %>% iconv("UTF-8")
head(title)
str(title)
# 開始斷詞
cutter <- worker()
ccset<-cutter[title]
head(ccset)
# 轉成data.frame
raw_data <- data.frame(ccset %>% table)
head(raw_data)
